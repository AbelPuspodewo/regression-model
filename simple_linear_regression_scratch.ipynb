{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Xb0PXC-sQuqV"
      },
      "outputs": [],
      "source": [
        "#Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z9PNA3AKb5M",
        "outputId": "f4a2cf01-7e28-42b3-e554-f854aff6b8d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#Upload dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-cwPbLbVLX2j",
        "outputId": "caf91c27-4d41-41d9-eab7-0a3e70935397"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c8e47bbf-bfc5-48dc-94df-9e8fa7280894\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>180</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8e47bbf-bfc5-48dc-94df-9e8fa7280894')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c8e47bbf-bfc5-48dc-94df-9e8fa7280894 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c8e47bbf-bfc5-48dc-94df-9e8fa7280894');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   x    y\n",
              "0  1    8\n",
              "1  2   21\n",
              "2  3   50\n",
              "3  4  101\n",
              "4  5  180"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "#Read the dataset as a pandas dataframe\n",
        "data = pd.read_excel('gdrive/My Drive/Stock Predicting/Dataset.xlsx')\n",
        "data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "ZBcX8e0pSRyX"
      },
      "outputs": [],
      "source": [
        "#Separate X(features) and Y(label), and convert into array\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, -1].values.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRie7Ppkxqyh",
        "outputId": "6869df3d-b243-4fe0-ddc6-93317ff17c9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "#Check the shape of X\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "-wi4CSnxJa9z"
      },
      "outputs": [],
      "source": [
        "#Splitting dataset into train and test (80% and 20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=41)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "_W8wtdRbXgrQ"
      },
      "outputs": [],
      "source": [
        "class LinearRegression():\n",
        "    def __init__(self, epochs, alpha):\n",
        "        ''' constructor '''\n",
        "        #Input hyperparameters\n",
        "        self.epochs = epochs\n",
        "        self.alpha = alpha\n",
        "        #Initial values for w and b\n",
        "        self.w = None\n",
        "        self.b = 0\n",
        "        \n",
        "    def forward_propagation(self,X,w,b):\n",
        "      # n: features, m = number of data\n",
        "      #X -> n x m\n",
        "      #w -> 1 x n\n",
        "      #b and z -> 1 x m\n",
        "      z = (np.dot(w,X))+b\n",
        "      return z\n",
        "\n",
        "    def cost_function(self,z,y):\n",
        "      m = y.shape[1]\n",
        "      J = (1/(2*m))*np.sum(np.square(z-y))\n",
        "      return J\n",
        "    \n",
        "    def back_propagation(self,X,y,z):\n",
        "      m = y.shape[0]\n",
        "      dz = (1/m)*(z-y)\n",
        "      dw = np.dot(dz,X.T)\n",
        "      db = np.sum(dz)\n",
        "      return dw,db\n",
        "    \n",
        "    def gradient_descent(self,w,b,dw,db,alpha):\n",
        "      w = w - self.alpha*dw\n",
        "      b = b - self.alpha*db\n",
        "      return w,b\n",
        "    \n",
        "    def fit(self, X_train, y_train, X_val, y_val, alpha, epochs):\n",
        "        ''' function to train the tree '''\n",
        "        #Store the number of data\n",
        "        m_train = y_train.shape[1]\n",
        "        m_val = y_val.shape[1]\n",
        "\n",
        "        #Store the number of features\n",
        "        num_features = X_train.shape[1]\n",
        "        print(num_features)\n",
        "\n",
        "        #Initialize parameters w and b\n",
        "        self.w = np.random.randn(1,num_features)\n",
        "        self.b = 0\n",
        "\n",
        "        #Transpose y_train\n",
        "        Y_train = y_train.T\n",
        "        X_train = X_train.T\n",
        "\n",
        "        #Variable for cost function plotting\n",
        "        cost = []\n",
        "        counter = []\n",
        "\n",
        "        for i in range(1,self.epochs+1):\n",
        "          z_train = self.forward_propagation(X_train,self.w,self.b)\n",
        "          cost_train = self.cost_function(z_train,Y_train)\n",
        "          print(z_train.shape)\n",
        "          print(Y_train.shape)\n",
        "          dw,db = self.back_propagation(X_train,Y_train,z_train)\n",
        "          self.w,self.b = self.gradient_descent(self.w,self.b,dw,db,alpha)\n",
        "          MAE_train = (1/m_train)*np.sum(np.abs(z_train-Y_train))\n",
        "          cost.append(cost_train)\n",
        "          counter.append(i)\n",
        "          #z_val = self.forward_propagation(X_val,w,b)\n",
        "          #cost_val = self.cost_function(z_val,y_val)\n",
        "          #MAE_val = (1/m_val)*np.sum(np.abs(z_val.T-y_val))\n",
        "          #print(MAE_train)\n",
        "          #print(MAE_val)\n",
        "\n",
        "          #print epochs dkk\n",
        "          print('Epochs '+str(i)+'/'+str(epochs)+': ')\n",
        "          print('Training Cost '+str(cost_train))\n",
        "          print('Training MAE '+str(MAE_train))\n",
        "\n",
        "        #Visualization Cost Function\n",
        "        #plt.scatter(counter, cost, color = 'black')\n",
        "        #plt.title('Minimize Cost Funtion')\n",
        "\n",
        "        #Visualization Accuracy\n",
        "        plt.scatter( X_train, Y_train, color = 'blue' )\n",
        "        #print(z_train)\n",
        "        plt.scatter( X_train, z_train, color = 'red' )\n",
        "        plt.title('Accuracy')\n",
        "        plt.show()\n",
        "\n",
        "        rms = mean_squared_error(Y_train, z_train, squared=False)\n",
        "        print(rms)\n",
        "    \n",
        "    \n",
        "    def predict(self, X_test, y_test):\n",
        "        m_test = y_test.shape[1]\n",
        "        Y_test = y_test.T\n",
        "        z_test = self.forward_propagation(X_test,self.w,self.b)\n",
        "        print(z_test.shape)\n",
        "        print(y_test.shape)\n",
        "        cost_test = self.cost_function(z_test,Y_test)\n",
        "        MAE_test = (1/m_test)*np.sum(np.abs(z_test-Y_test))\n",
        "        print(z_test)\n",
        "        print(cost_test)\n",
        "        print(MAE_test)\n",
        "    \n",
        "    #Kalo w sama b local var: predict nya gabisa\n",
        "    #Kalo w sama b global di __init__: ga ke update tiap epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "65xEMTkrk6v3"
      },
      "outputs": [],
      "source": [
        "#define hyperparameters\n",
        "alpha = 10e-8\n",
        "epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b_USpPEMQ-A8",
        "outputId": "6d008c27-f85c-4a0a-89a7-55782e2da126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 1/100: \n",
            "Training Cost 81557965805.31131\n",
            "Training MAE 21786486.433647707\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 2/100: \n",
            "Training Cost 77748306623.69818\n",
            "Training MAE 21070025.62711607\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 3/100: \n",
            "Training Cost 74148806354.72652\n",
            "Training MAE 20399076.455093496\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 4/100: \n",
            "Training Cost 70747871567.12688\n",
            "Training MAE 19768581.303208947\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 5/100: \n",
            "Training Cost 67534548382.085464\n",
            "Training MAE 19180729.143826235\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 6/100: \n",
            "Training Cost 64498487192.28765\n",
            "Training MAE 18620417.262072675\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 7/100: \n",
            "Training Cost 61629909327.23807\n",
            "Training MAE 18087953.325286373\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 8/100: \n",
            "Training Cost 58919575557.49058\n",
            "Training MAE 17591329.04386288\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 9/100: \n",
            "Training Cost 56358756336.3446\n",
            "Training MAE 17117225.300777353\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 10/100: \n",
            "Training Cost 53939203683.16049\n",
            "Training MAE 16668622.265991366\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 11/100: \n",
            "Training Cost 51653124617.733765\n",
            "Training MAE 16248260.714930724\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 12/100: \n",
            "Training Cost 49493156060.163795\n",
            "Training MAE 15848835.169469485\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 13/100: \n",
            "Training Cost 47452341115.37331\n",
            "Training MAE 15478037.346308181\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 14/100: \n",
            "Training Cost 45524106665.893776\n",
            "Training MAE 15131463.884049762\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 15/100: \n",
            "Training Cost 43702242200.74656\n",
            "Training MAE 14800599.19449132\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 16/100: \n",
            "Training Cost 41980879812.23024\n",
            "Training MAE 14492008.99075379\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 17/100: \n",
            "Training Cost 40354475296.18659\n",
            "Training MAE 14204699.98184062\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 18/100: \n",
            "Training Cost 38817790294.87174\n",
            "Training MAE 13938330.852217223\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 19/100: \n",
            "Training Cost 37365875424.91714\n",
            "Training MAE 13691511.193602474\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 20/100: \n",
            "Training Cost 35994054336.03766\n",
            "Training MAE 13462465.005088095\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 21/100: \n",
            "Training Cost 34697908649.142265\n",
            "Training MAE 13250137.32409893\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 22/100: \n",
            "Training Cost 33473263725.33487\n",
            "Training MAE 13053464.57438868\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 23/100: \n",
            "Training Cost 32316175219.969223\n",
            "Training MAE 12871374.886852046\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 24/100: \n",
            "Training Cost 31222916378.450348\n",
            "Training MAE 12703839.029744862\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 25/100: \n",
            "Training Cost 30189966032.86399\n",
            "Training MAE 12549827.210089216\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 26/100: \n",
            "Training Cost 29213997260.772827\n",
            "Training MAE 12401144.572052231\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 27/100: \n",
            "Training Cost 28291866669.650978\n",
            "Training MAE 12260352.205904286\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 28/100: \n",
            "Training Cost 27420604272.44354\n",
            "Training MAE 12129561.652150251\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 29/100: \n",
            "Training Cost 26597403921.64143\n",
            "Training MAE 12011482.036292043\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 30/100: \n",
            "Training Cost 25819614271.061295\n",
            "Training MAE 11896705.18970424\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 31/100: \n",
            "Training Cost 25084730236.219456\n",
            "Training MAE 11785703.088825304\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 32/100: \n",
            "Training Cost 24390384925.794888\n",
            "Training MAE 11686114.926673913\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 33/100: \n",
            "Training Cost 23734342018.193604\n",
            "Training MAE 11593128.676777795\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 34/100: \n",
            "Training Cost 23114488558.660484\n",
            "Training MAE 11507544.492483646\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 35/100: \n",
            "Training Cost 22528828153.73883\n",
            "Training MAE 11424354.051026013\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 36/100: \n",
            "Training Cost 21975474541.158146\n",
            "Training MAE 11343490.390317082\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 37/100: \n",
            "Training Cost 21452645514.43944\n",
            "Training MAE 11271807.104499105\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 38/100: \n",
            "Training Cost 20958657182.650143\n",
            "Training MAE 11203254.582673308\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 39/100: \n",
            "Training Cost 20491918546.82002\n",
            "Training MAE 11143378.472334376\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 40/100: \n",
            "Training Cost 20050926375.54951\n",
            "Training MAE 11086144.463340513\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 41/100: \n",
            "Training Cost 19634260363.30552\n",
            "Training MAE 11035964.396643184\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 42/100: \n",
            "Training Cost 19240578555.81004\n",
            "Training MAE 10989121.728427155\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 43/100: \n",
            "Training Cost 18868613027.78775\n",
            "Training MAE 10946586.274700433\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 44/100: \n",
            "Training Cost 18517165799.150734\n",
            "Training MAE 10909269.392453812\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 45/100: \n",
            "Training Cost 18185104976.467358\n",
            "Training MAE 10872996.02729262\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 46/100: \n",
            "Training Cost 17871361107.28715\n",
            "Training MAE 10843784.698433176\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 47/100: \n",
            "Training Cost 17574923735.579678\n",
            "Training MAE 10815985.666741064\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 48/100: \n",
            "Training Cost 17294838147.19287\n",
            "Training MAE 10789972.365976982\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 49/100: \n",
            "Training Cost 17030202294.848372\n",
            "Training MAE 10769915.708907502\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 50/100: \n",
            "Training Cost 16780163892.769667\n",
            "Training MAE 10750419.733975492\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 51/100: \n",
            "Training Cost 16543917671.585407\n",
            "Training MAE 10732241.780398589\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 52/100: \n",
            "Training Cost 16320702784.666014\n",
            "Training MAE 10719608.576508123\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 53/100: \n",
            "Training Cost 16109800357.540028\n",
            "Training MAE 10707328.392651292\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 54/100: \n",
            "Training Cost 15910531172.49704\n",
            "Training MAE 10695391.35351624\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 55/100: \n",
            "Training Cost 15722253480.919651\n",
            "Training MAE 10683787.860041125\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 56/100: \n",
            "Training Cost 15544360936.29831\n",
            "Training MAE 10672508.58168637\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 57/100: \n",
            "Training Cost 15376280641.271528\n",
            "Training MAE 10661544.448923055\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 58/100: \n",
            "Training Cost 15217471302.401295\n",
            "Training MAE 10650886.645931482\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 59/100: \n",
            "Training Cost 15067421486.740345\n",
            "Training MAE 10645371.007090077\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 60/100: \n",
            "Training Cost 14925647974.57611\n",
            "Training MAE 10640048.744715773\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 61/100: \n",
            "Training Cost 14791694203.045649\n",
            "Training MAE 10634874.988344757\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 62/100: \n",
            "Training Cost 14665128795.60862\n",
            "Training MAE 10629845.583700199\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 63/100: \n",
            "Training Cost 14545544172.642027\n",
            "Training MAE 10628034.13314237\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 64/100: \n",
            "Training Cost 14432555238.681595\n",
            "Training MAE 10627580.901949411\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 65/100: \n",
            "Training Cost 14325798142.081562\n",
            "Training MAE 10627139.972588541\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 66/100: \n",
            "Training Cost 14224929103.097929\n",
            "Training MAE 10626711.00093146\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 67/100: \n",
            "Training Cost 14129623306.620575\n",
            "Training MAE 10626293.652476447\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 68/100: \n",
            "Training Cost 14039573855.987898\n",
            "Training MAE 10628741.421128849\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 69/100: \n",
            "Training Cost 13954490784.514332\n",
            "Training MAE 10632129.731061192\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 70/100: \n",
            "Training Cost 13874100121.547022\n",
            "Training MAE 10635422.881804112\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 71/100: \n",
            "Training Cost 13798143010.043531\n",
            "Training MAE 10638623.535322662\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 72/100: \n",
            "Training Cost 13726374872.82849\n",
            "Training MAE 10641734.279116604\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 73/100: \n",
            "Training Cost 13658564624.843693\n",
            "Training MAE 10644757.628303498\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 74/100: \n",
            "Training Cost 13594493928.854507\n",
            "Training MAE 10647696.027643505\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 75/100: \n",
            "Training Cost 13533956492.215279\n",
            "Training MAE 10650551.853507549\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 76/100: \n",
            "Training Cost 13476757402.428745\n",
            "Training MAE 10653327.41579042\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 77/100: \n",
            "Training Cost 13422712499.359337\n",
            "Training MAE 10656024.959770368\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 78/100: \n",
            "Training Cost 13371647782.078367\n",
            "Training MAE 10658646.667916678\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 79/100: \n",
            "Training Cost 13323398848.430702\n",
            "Training MAE 10661194.661646668\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 80/100: \n",
            "Training Cost 13277810365.517708\n",
            "Training MAE 10663671.003033547\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 81/100: \n",
            "Training Cost 13234735569.391087\n",
            "Training MAE 10668078.418645605\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 82/100: \n",
            "Training Cost 13194035792.346123\n",
            "Training MAE 10673106.448769543\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 83/100: \n",
            "Training Cost 13155580016.291851\n",
            "Training MAE 10677993.452682246\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 84/100: \n",
            "Training Cost 13119244450.75953\n",
            "Training MAE 10682743.375423748\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 85/100: \n",
            "Training Cost 13084912134.190397\n",
            "Training MAE 10687360.051676318\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 86/100: \n",
            "Training Cost 13052472557.218346\n",
            "Training MAE 10691847.208851587\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 87/100: \n",
            "Training Cost 13021821306.734253\n",
            "Training MAE 10696208.470091306\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 88/100: \n",
            "Training Cost 12992859729.585566\n",
            "Training MAE 10700447.357184172\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 89/100: \n",
            "Training Cost 12965494614.827837\n",
            "Training MAE 10704567.293401072\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 90/100: \n",
            "Training Cost 12939637893.504982\n",
            "Training MAE 10709903.872822335\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 91/100: \n",
            "Training Cost 12915206354.991096\n",
            "Training MAE 10715907.013218133\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 92/100: \n",
            "Training Cost 12892121378.980331\n",
            "Training MAE 10721741.852389786\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 93/100: \n",
            "Training Cost 12870308682.26159\n",
            "Training MAE 10727413.098363148\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 94/100: \n",
            "Training Cost 12849698079.462328\n",
            "Training MAE 10732925.327462679\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 95/100: \n",
            "Training Cost 12830223256.991087\n",
            "Training MAE 10738282.987995654\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 96/100: \n",
            "Training Cost 12811821559.450333\n",
            "Training MAE 10743490.403833278\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 97/100: \n",
            "Training Cost 12794433787.831987\n",
            "Training MAE 10748551.77789163\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 98/100: \n",
            "Training Cost 12778004008.845428\n",
            "Training MAE 10753471.19551526\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 99/100: \n",
            "Training Cost 12762479374.763964\n",
            "Training MAE 10758252.627766088\n",
            "(1, 80)\n",
            "(1, 80)\n",
            "Epochs 100/100: \n",
            "Training Cost 12747809953.209482\n",
            "Training MAE 10762899.934620332\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "134536.24918275414\n"
          ]
        }
      ],
      "source": [
        "regressor = LinearRegression(epochs,alpha)\n",
        "regressor.fit(X_train, y_train, X_test, y_test, alpha, epochs)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "simple_linear_regression_scratch",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}